{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b19fd9b5-d93d-42bf-ac5a-d1b6f563fe7c",
   "metadata": {},
   "source": [
    "# L3: Custom Components - News Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9285fcf-223f-407d-aafd-e17ac1c2a830",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75222381-4e42-438f-8e5e-d06aaf03f9d7",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from helper import load_env\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "load_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ba8b60d-aa47-4581-b04e-5efb51ebfeb3",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from haystack import Document, Pipeline, component\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.generators.openai import OpenAIGenerator\n",
    "from haystack.components.fetchers import LinkContentFetcher\n",
    "from haystack.components.converters import HTMLToDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd4de72-ce05-48fc-9ce5-eb9e735624bb",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6ff; padding:15px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\"> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. For more help, please see the <em>\"Appendix - Tips and Help\"</em> Lesson.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ea46f0-c25b-4655-baaa-28dd351545f1",
   "metadata": {},
   "source": [
    "## Custom Component Requirements\n",
    "#### Build a Custom Component\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac45560-854f-49ff-a922-1ae66f814c20",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "@component\n",
    "class Greeter:\n",
    "\n",
    "    @component.output_types(greeting=str)\n",
    "    def run(self, user_name: str):\n",
    "        return {\"greeting\": f\"Hello {user_name}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c70499c-a376-484a-8543-6aa7fea52429",
   "metadata": {},
   "source": [
    "#### Run the Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eed3129-6b20-4306-b24f-70f4fad48f1b",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'greeting': 'Hello Tuana'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greeter = Greeter()\n",
    "\n",
    "greeter.run(user_name=\"Tuana\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b68d01-aeab-4460-98ee-0537bbc23271",
   "metadata": {},
   "source": [
    "#### Add the Component to a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92f65838-50ac-4634-af7a-d6874d75ce19",
   "metadata": {
    "height": 285
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7fd7b2c09390>\n",
       "üöÖ Components\n",
       "  - greeter: Greeter\n",
       "  - prompt: PromptBuilder\n",
       "  - llm: OpenAIGenerator\n",
       "üõ§Ô∏è Connections\n",
       "  - greeter.greeting -> prompt.dialogue (str)\n",
       "  - prompt.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greeter = Greeter()\n",
    "template = \"\"\" You will be given the beginning of a dialogue. \n",
    "Create a short play script using this as the start of the play.\n",
    "Start of dialogue: {{ dialogue }}\n",
    "Full script: \n",
    "\"\"\"\n",
    "prompt = PromptBuilder(template=template)\n",
    "llm = OpenAIGenerator()\n",
    "\n",
    "dialogue_builder = Pipeline()\n",
    "dialogue_builder.add_component(\"greeter\", greeter)\n",
    "dialogue_builder.add_component(\"prompt\", prompt)\n",
    "dialogue_builder.add_component(\"llm\", llm)\n",
    "\n",
    "dialogue_builder.connect(\"greeter.greeting\", \"prompt.dialogue\")\n",
    "dialogue_builder.connect(\"prompt\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ae3b13-f2a3-48fc-9c18-bd1654cc251e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "dialogue_builder.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e31ee703-6af6-4560-9e28-a057c06541d6",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters:\n",
      "SARAH - A young woman in her 20s\n",
      "TIANA - Sarah's best friend\n",
      "\n",
      "(As the lights come up, SARAH is sitting on a park bench, looking down at her phone. TIANA walks up to her.)\n",
      "\n",
      "TIANA: Hello Tuana.\n",
      "\n",
      "SARAH: (looks up, surprised) Tiana? What are you doing here? I thought you were out of town.\n",
      "\n",
      "TIANA: I was, but I had to come back early. (sits down next to Sarah) What's been going on with you? You seem really distracted.\n",
      "\n",
      "SARAH: (sighs) I've just been going through a lot lately. Work has been overwhelming, I'm having trouble with my boyfriend, and I just feel like everything is falling apart.\n",
      "\n",
      "TIANA: I'm so sorry, Sarah. I wish you had told me sooner. You know I'm here for you, right?\n",
      "\n",
      "SARAH: I know, Tiana. And I appreciate that more than you know. I just feel like I'm drowning in all this stress and I don't know how to cope.\n",
      "\n",
      "TIANA: Well, how about this? Let's take a break from all the chaos and go grab some coffee. We can sit and chat and just take a moment to breathe. How does that sound?\n",
      "\n",
      "SARAH: (smiling) That sounds perfect. Thank you, Tiana. (stands up) Let's go before I change my mind.\n",
      "\n",
      "(They both walk offstage, arm in arm, as the lights fade to black.) \n",
      "\n",
      "-End-\n"
     ]
    }
   ],
   "source": [
    "dialogue = dialogue_builder.run({\"greeter\": {\"user_name\": \"Tuana\"}})\n",
    "\n",
    "print(dialogue[\"llm\"][\"replies\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f3d9c4-3407-47d1-a5bf-0cb04abba62b",
   "metadata": {},
   "source": [
    "## Build a Hacker News Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a30a26a",
   "metadata": {},
   "source": [
    "> **Note:** Everyone will get different results for this application to what you see in the recording. Results depend on when you run it as it's based on 'current' top/new posts on Hacker News. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "602c88fa-ce22-46f9-9ae8-1bf49f2f6162",
   "metadata": {
    "height": 149
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'by': 'brig90', 'descendants': 54, 'id': 44022353, 'kids': [44023494, 44024081, 44022718, 44024059, 44023668, 44022679, 44023233, 44022579, 44022597, 44023944, 44023829, 44023658, 44023866, 44022560, 44023644, 44022686, 44022868, 44022550], 'score': 202, 'text': 'I built this project as a way to learn more about NLP by applying it to something weird and unsolved.<p>The Voynich Manuscript is a 15th-century book written in an unknown script. No one‚Äôs been able to translate it, and many think it‚Äôs a hoax, a cipher, or a constructed language. I wasn‚Äôt trying to decode it ‚Äî I just wanted to see: does it behave like a structured language?<p>I stripped a handful of common suffix-like endings (aiin, dy, etc.) to isolate what looked like root forms. I know that‚Äôs a strong assumption ‚Äî I call it out directly in the repo ‚Äî but it helped clarify the clustering. From there, I used SBERT embeddings and KMeans to group similar roots, inferred POS-like roles based on position and frequency, and built a Markov transition matrix to visualize cluster-to-cluster flow.<p>It‚Äôs not translation. It‚Äôs not decryption. It‚Äôs structural modeling ‚Äî and it revealed some surprisingly consistent syntax across the manuscript, especially when broken out by section (Botanical, Biological, etc.).<p>GitHub repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;brianmg&#x2F;voynich-nlp-analysis\">https:&#x2F;&#x2F;github.com&#x2F;brianmg&#x2F;voynich-nlp-analysis</a>\\nWrite-up: <a href=\"https:&#x2F;&#x2F;brig90.substack.com&#x2F;p&#x2F;modeling-the-voynich-manuscript-with?r=3z5dn9\" rel=\"nofollow\">https:&#x2F;&#x2F;brig90.substack.com&#x2F;p&#x2F;modeling-the-voynich-manuscrip...</a><p>I‚Äôm new to the NLP space, so I‚Äôm sure there are things I got wrong ‚Äî but I‚Äôd love feedback from people who‚Äôve worked with structured language modeling or weird edge cases like this.', 'time': 1747584541, 'title': 'Show HN: I modeled the Voynich Manuscript with SBERT to test for structure', 'type': 'story', 'url': 'https://github.com/brianmg/voynich-nlp-analysis'}\n"
     ]
    }
   ],
   "source": [
    "trending_list = requests.get(\n",
    "        url=\"https://hacker-news.firebaseio.com/v0/topstories.json?print=pretty\"\n",
    "    )\n",
    "post = requests.get(\n",
    "    url=f\"https://hacker-news.firebaseio.com/v0/item/{trending_list.json()[0]}.json?print=pretty\"\n",
    ")\n",
    "\n",
    "print(post.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c137b62-9b91-4273-872b-e0010d03ad4f",
   "metadata": {
    "height": 642
   },
   "outputs": [],
   "source": [
    "@component\n",
    "class HackernewsNewestFetcher:\n",
    "    def __init__(self):\n",
    "        fetcher = LinkContentFetcher()\n",
    "        converter = HTMLToDocument()\n",
    "\n",
    "        html_conversion_pipeline = Pipeline()\n",
    "        html_conversion_pipeline.add_component(\"fetcher\", fetcher)\n",
    "        html_conversion_pipeline.add_component(\"converter\", converter)\n",
    "\n",
    "        html_conversion_pipeline.connect(\"fetcher\", \"converter\")\n",
    "        self.html_pipeline = html_conversion_pipeline\n",
    "        \n",
    "    @component.output_types(articles=List[Document])\n",
    "    def run(self, top_k: int):\n",
    "        articles = []\n",
    "        trending_list = requests.get(\n",
    "            url=\"https://hacker-news.firebaseio.com/v0/topstories.json?print=pretty\"\n",
    "        )\n",
    "        for id in trending_list.json()[0:top_k]:\n",
    "            post = requests.get(\n",
    "                url=f\"https://hacker-news.firebaseio.com/v0/item/{id}.json?print=pretty\"\n",
    "            )\n",
    "            if \"url\" in post.json():\n",
    "                try:\n",
    "                    article = self.html_pipeline.run(\n",
    "                        {\"fetcher\": {\"urls\": [post.json()[\"url\"]]}}\n",
    "                    )\n",
    "                    articles.append(article[\"converter\"][\"documents\"][0])\n",
    "                except:\n",
    "                    print(f\"Can't download {post}, skipped\")\n",
    "            elif \"text\" in post.json():\n",
    "                try:\n",
    "                    articles.append(Document(content=post.json()[\"text\"], meta= {\"title\": post.json()[\"title\"]}))\n",
    "                except:\n",
    "                    print(f\"Can't download {post}, skipped\")\n",
    "        return {\"articles\": articles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9b4eec2-35f8-47d2-bd11-3389e66a6549",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id=917409cb3d5e8930aa4ac860c20c96e4650140018a7cc9f3c7a168d9ac209a23, content: 'This started as a personal challenge to figure out what modern NLP could tell us about the Voynich M...', meta: {'content_type': 'text/html', 'url': 'https://github.com/brianmg/voynich-nlp-analysis'}), Document(id=3491a2d399c559c9f59f8daecb3bd14763ee767652ffdc140ccd27ad5fc38834, content: 'Spaced repetition recap\n",
      "Mastering any subject is built on a foundation of knowledge: knowledge of fa...', meta: {'content_type': 'text/html', 'url': 'https://domenic.me/fsrs/'}), Document(id=e9d7ab13b83e59581de2351d24351fa5dd086ebfbdc194f26011bd231d3329c9, content: 'Ditching Obsidian and building my own\n",
      "Amber Williams\n",
      "May 5, 2025 ¬∑ 8 mins\n",
      "\"You can‚Äôt really know whe...', meta: {'content_type': 'text/html', 'url': 'https://amberwilliams.io/blogs/building-my-own-pkms'})]\n"
     ]
    }
   ],
   "source": [
    "fetcher = HackernewsNewestFetcher()\n",
    "results = fetcher.run(top_k=3)\n",
    "\n",
    "print(results['articles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6550e471-da4c-4526-9010-acb20841975f",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"  \n",
    "You will be provided a few of the top posts in HackerNews.  \n",
    "For each post, provide a brief summary if possible.\n",
    "  \n",
    "Posts:  \n",
    "{% for article in articles %}\n",
    "  Post:\\n\n",
    "  {{ article.content}}\n",
    "{% endfor %}  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d8a7332-252a-42f7-8f63-841e4e87bc2f",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7fd7b2c5de10>\n",
       "üöÖ Components\n",
       "  - fetcher: HackernewsNewestFetcher\n",
       "  - prompt: PromptBuilder\n",
       "  - llm: OpenAIGenerator\n",
       "üõ§Ô∏è Connections\n",
       "  - fetcher.articles -> prompt.articles (List[Document])\n",
       "  - prompt.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_builder = PromptBuilder(template=prompt_template)\n",
    "fetcher = HackernewsNewestFetcher()\n",
    "llm = OpenAIGenerator()\n",
    "\n",
    "summarizer_pipeline = Pipeline()\n",
    "summarizer_pipeline.add_component(\"fetcher\", fetcher)\n",
    "summarizer_pipeline.add_component(\"prompt\", prompt_builder)\n",
    "summarizer_pipeline.add_component(\"llm\", llm)\n",
    "\n",
    "summarizer_pipeline.connect(\"fetcher.articles\", \"prompt.articles\")\n",
    "summarizer_pipeline.connect(\"prompt\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d00c67-37c1-47d7-8a93-f23c6f962218",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "summarizer_pipeline.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69ea7955-1ce9-4ce7-8c1c-d8f0289b52e6",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post 1: \n",
      "The post discusses a project to analyze the Voynich Manuscript using modern NLP techniques to understand its structure without attempting a translation. The project involved clustering of words, deriving a lexicon hypothesis, and examining cluster similarities to real-world languages. The project aimed to model the manuscript's structure using computational linguistics and offers insights into the organization of the mysterious manuscript.\n",
      "\n",
      "Post 2: \n",
      "The post explores the concept of spaced repetition as a method to enhance learning and knowledge retention. It delves into the development of a new scheduling algorithm, FSRS, that has improved spaced repetition systems by optimizing review intervals based on the probability of recall. The impact of FSRS on efficient learning is discussed, along with comparisons to other existing spaced repetition algorithms.\n",
      "\n",
      "Post 3: \n",
      "In this post, the author shares their journey of ditching commercial note-taking apps like Obsidian and instead, building their own personal knowledge management system (PKMS). The post highlights the motivation behind creating a secure, easy-to-use, and lasting note vault, free from monthly fees and privacy concerns associated with mainstream applications. The author details the process of building and hosting their PKMS, emphasizing control, security, and accessibility as key factors in their decision.\n"
     ]
    }
   ],
   "source": [
    "summaries = summarizer_pipeline.run({\"fetcher\": {\"top_k\": 3}})\n",
    "\n",
    "print(summaries[\"llm\"][\"replies\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6d0a5e8-382f-484d-9834-facf87daf9fd",
   "metadata": {
    "height": 387
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7fd7b0728f50>\n",
       "üöÖ Components\n",
       "  - fetcher: HackernewsNewestFetcher\n",
       "  - prompt: PromptBuilder\n",
       "  - llm: OpenAIGenerator\n",
       "üõ§Ô∏è Connections\n",
       "  - fetcher.articles -> prompt.articles (List[Document])\n",
       "  - prompt.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"  \n",
    "You will be provided a few of the top posts in HackerNews, followed by their URL.  \n",
    "For each post, provide a brief summary followed by the URL the full post can be found at.  \n",
    "  \n",
    "Posts:  \n",
    "{% for article in articles %}  \n",
    "  {{ article.content }}\n",
    "  URL: {{ article.meta[\"url\"] }}\n",
    "{% endfor %}  \n",
    "\"\"\"\n",
    "\n",
    "prompt_builder = PromptBuilder(template=prompt_template)\n",
    "fetcher = HackernewsNewestFetcher()\n",
    "llm = OpenAIGenerator()\n",
    "\n",
    "summarizer_pipeline = Pipeline()\n",
    "summarizer_pipeline.add_component(\"fetcher\", fetcher)\n",
    "summarizer_pipeline.add_component(\"prompt\", prompt_builder)\n",
    "summarizer_pipeline.add_component(\"llm\", llm)\n",
    "\n",
    "summarizer_pipeline.connect(\"fetcher.articles\", \"prompt.articles\")\n",
    "summarizer_pipeline.connect(\"prompt\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4c71d92-aff4-4118-be3d-4cd0de4039cf",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: This post discusses the use of spaced repetition systems in learning and how a new scheduling algorithm known as FSRS has revolutionized the efficiency and effectiveness of these systems. The FSRS algorithm focuses on predicting when the probability of recalling information drops to 90% and uses machine learning to optimize scheduling intervals. The post explains how FSRS works, its parameters, and its practical applications in tools like Anki for language learning. A comparison is made with other popular language learning platforms like WaniKani and Bunpro, highlighting the superior performance of FSRS in retaining knowledge.\n",
      "\n",
      "URL: https://domenic.me/fsrs/  \n"
     ]
    }
   ],
   "source": [
    "summaries = summarizer_pipeline.run({\"fetcher\": {\"top_k\": 2}})\n",
    "\n",
    "print(summaries[\"llm\"][\"replies\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6ba161",
   "metadata": {},
   "source": [
    "### Extra resources! \n",
    "\n",
    "Learn more about the Haystack integrations:\n",
    "\n",
    "* [deepset-ai github repo](https://github.com/deepset-ai/haystack-integrations)\n",
    "* [haystack.deepset.ai/integrations](https://haystack.deepset.ai/integrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824831c7-7ff3-47ef-8405-55b9b30a1ae2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cf5e9c-705f-4759-96b6-5df37f42ae27",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debdf3e3-33cd-4e22-9c7b-123b71ff681a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce245c-2ce5-441b-8979-9b376cc46c58",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ba71cc-2675-428a-a3de-417112ce1151",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
