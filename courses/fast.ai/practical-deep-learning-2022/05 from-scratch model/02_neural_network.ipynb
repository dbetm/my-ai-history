{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup - Titanic problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "datasets_base_path = \"../../../../datasets\"\n",
    "trainset_path = os.path.join(datasets_base_path, \"titanic_train.csv\")\n",
    "testset_path = os.path.join(datasets_base_path, \"titanic_test.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  \\\n",
       "0         1           0         0         0         1           0           0   \n",
       "1         0           1         1         0         0           1           0   \n",
       "2         0           1         0         0         1           0           0   \n",
       "3         0           1         1         0         0           0           0   \n",
       "4         1           0         0         0         1           0           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(trainset_path)\n",
    "# We will inpute the missing values with the mode\n",
    "modes = df_train.mode().iloc[0]\n",
    "df_train.fillna(modes, inplace=True)\n",
    "\n",
    "\n",
    "df_train[\"LogFare\"] = np.log(df_train[\"Fare\"] + 1)\n",
    "\n",
    "\n",
    "# Clearly we need to change the string values by numeric ones. We will use dummy variables.\n",
    "df_train = pd.get_dummies(data=df_train, columns=[\"Sex\", \"Pclass\", \"Embarked\"])\n",
    "# Cabin, Name, and Ticket have too many unique values for it to make sense creating \n",
    "# dummy variables for them.\n",
    "\n",
    "added_columns = [\n",
    "    \"Sex_male\",\n",
    "    \"Sex_female\",\n",
    "    \"Pclass_1\",\n",
    "    \"Pclass_2\",\n",
    "    \"Pclass_3\",\n",
    "    \"Embarked_C\",\n",
    "    \"Embarked_Q\",\n",
    "    \"Embarked_S\"\n",
    "]\n",
    "\n",
    "df_train[added_columns].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22.0000,  1.0000,  0.0000,  2.1102,  1.0000,  0.0000,  0.0000,  0.0000,\n",
       "          1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [38.0000,  1.0000,  0.0000,  4.2806,  0.0000,  1.0000,  1.0000,  0.0000,\n",
       "          0.0000,  1.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor(data=df_train[\"Survived\"])\n",
    "\n",
    "\n",
    "# The independent variables are all the continuous variables and all the dummy \n",
    "# variables just created\n",
    "independent_cols = [\"Age\", \"SibSp\", \"Parch\", \"LogFare\"] + added_columns\n",
    "\n",
    "x = torch.tensor(df_train[independent_cols].values, dtype=torch.float)\n",
    "x[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_COEFFS = x.shape[1] # number of columns in X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2750, 0.1250, 0.0000, 0.3381, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
       "         0.0000, 0.0000, 1.0000]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalization\n",
    "vals, indices = x.max(dim=0)\n",
    "x = x / vals # is dividing a matrix by a vector, using broadcasting\n",
    "\n",
    "x[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastcore.foundation.L"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.data.transforms import RandomSplitter\n",
    "\n",
    "trn_split, val_split = RandomSplitter(seed=42)(df_train)\n",
    "\n",
    "type(trn_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713, 178)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_x, val_x = x[trn_split], x[val_split]\n",
    "trn_y, val_y = y[trn_split], y[val_split]\n",
    "\n",
    "len(trn_x),len(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn our dependent variable into a column vector,\n",
    "\n",
    "trn_y = trn_y[:, None]\n",
    "val_y = val_y[:, None]\n",
    "\n",
    "val_y[:2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will build a NN with a hidden layer to solve the Titanic dataset (from Kaggle competition).\n",
    "\n",
    "The simple neural network will have a layer with N inputs equal to the number of coefficients (`n_coeff`)\n",
    "and then `n_hidden` neurons in the hidden layer -- `MATRIX W_0=(n_coeff, n_hidden)` --, finally the second layer will take `n_hidden` inputs and create a single output, in addition a bias term (independent) -- `MATRIX W_1=(n_hidden, 1), BIAS B = <SCALAR>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs(n_coeffs, n_hidden: int = 10):\n",
    "    layer_1 = (torch.rand(n_coeffs, n_hidden) - 0.5) / n_hidden\n",
    "    layer_2 = torch.rand(n_hidden, 1) - 0.3\n",
    "    bias = torch.rand(1)[0]\n",
    "\n",
    "    return layer_1.requires_grad_(), layer_2.requires_grad_(), bias.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def calc_preds(coeffs, indeps):\n",
    "    layer_1, layer_2, const = coeffs\n",
    "    res = F.relu(indeps@layer_1)\n",
    "    res = res@layer_2 + const\n",
    "    # note that the output layer pass through the sigmoid function to make sure\n",
    "    # everything is between 0 and 1\n",
    "    return torch.sigmoid(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs, lr):\n",
    "    \"\"\"Update each layer of parameters / coefficients and reset gradient values.\"\"\"\n",
    "    for layer in coeffs:\n",
    "        layer.sub_(layer.grad * lr)\n",
    "        layer.grad.zero_()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(coeffs, indeps, deps):\n",
    "    # perform MAE using preds and Y (ground truth)\n",
    "    return torch.abs(calc_preds(coeffs, indeps) - deps).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch(coeffs, lr, train_x, train_y):\n",
    "    loss = calc_loss(coeffs, train_x, train_y)\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        update_coeffs(coeffs, lr)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs: int = 30, lr: float = 0.01):\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    coeffs = init_coeffs(N_COEFFS, n_hidden=10)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loss = one_epoch(coeffs, lr=lr, train_x=trn_x, train_y=trn_y)\n",
    "\n",
    "        print(f\"epoch: {epoch},\", f\"{loss:.3f}\")\n",
    "\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, 0.554\n",
      "epoch: 1, 0.515\n",
      "epoch: 2, 0.436\n",
      "epoch: 3, 0.311\n",
      "epoch: 4, 0.245\n",
      "epoch: 5, 0.225\n",
      "epoch: 6, 0.217\n",
      "epoch: 7, 0.212\n",
      "epoch: 8, 0.209\n",
      "epoch: 9, 0.206\n",
      "epoch: 10, 0.204\n",
      "epoch: 11, 0.202\n",
      "epoch: 12, 0.201\n",
      "epoch: 13, 0.199\n",
      "epoch: 14, 0.199\n",
      "epoch: 15, 0.198\n",
      "epoch: 16, 0.197\n",
      "epoch: 17, 0.197\n",
      "epoch: 18, 0.196\n",
      "epoch: 19, 0.196\n",
      "epoch: 20, 0.196\n",
      "epoch: 21, 0.196\n",
      "epoch: 22, 0.195\n",
      "epoch: 23, 0.195\n",
      "epoch: 24, 0.195\n",
      "epoch: 25, 0.195\n",
      "epoch: 26, 0.195\n",
      "epoch: 27, 0.194\n",
      "epoch: 28, 0.194\n",
      "epoch: 29, 0.194\n"
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(coeffs, val_x, val_y, threshold: float = 0.5):\n",
    "    return (val_y.bool() == (calc_preds(coeffs, val_x) > threshold)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(coeffs, val_x, val_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network\n",
    "\n",
    "\n",
    "We will add more hidden layers in order to make our neural network deep."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice here that there's a lot of messy constants to get the random numbers in just the right ranges. When you train the model in a moment, you'll see that the tiniest changes to these initialisations can cause our model to fail to train at all! This is a key reason that deep learning failed to make much progress in the early days. In the future we will learn about that initialisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs(n_coeffs, hiddens = [10, 10], debug: bool = False):\n",
    "    \"\"\"hidddens contains the size of each hidden layer that you want.\"\"\"\n",
    "    sizes = [n_coeffs] + hiddens + [1]\n",
    "    n = len(sizes)\n",
    "\n",
    "    if debug:\n",
    "        print(\"N:\", n)\n",
    "\n",
    "    layers = [(torch.rand(sizes[i], sizes[i+1]) - 0.3) / sizes[i+1] * 4 for i in range(n-1)]\n",
    "    consts = [(torch.rand(1)[0] - 0.5) * 0.1 for i in range(n-1)]\n",
    "\n",
    "    if debug:\n",
    "        print(\"LAYERS:\", len(layers))\n",
    "        print(\"BIASES\", len(consts))\n",
    "\n",
    "    for layer in layers+consts:\n",
    "        layer.requires_grad_()\n",
    "\n",
    "    return layers,consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 4\n",
      "LAYERS: 3\n",
      "BIASES 3\n"
     ]
    }
   ],
   "source": [
    "_ = init_coeffs(N_COEFFS, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(coeffs, indeps):\n",
    "    layers, consts = coeffs\n",
    "    n = len(layers)\n",
    "    res = indeps\n",
    "\n",
    "    for i, layer in enumerate(layers):\n",
    "        res = res@layer + consts[i]\n",
    "\n",
    "        if i != (n-1):\n",
    "            res = F.relu(res)\n",
    "\n",
    "    return torch.sigmoid(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs, lr):\n",
    "    layers, consts = coeffs\n",
    "\n",
    "    for layer in layers + consts:\n",
    "        layer.sub_(layer.grad * lr)\n",
    "        layer.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs: int = 20, lr: float = 0.01):\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    coeffs = init_coeffs(N_COEFFS)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loss = one_epoch(coeffs, lr=lr, train_x=trn_x, train_y=trn_y)\n",
    "\n",
    "        print(f\"epoch: {epoch},\", f\"{loss:.3f}\")\n",
    "\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, 0.548\n",
      "epoch: 1, 0.496\n",
      "epoch: 2, 0.490\n",
      "epoch: 3, 0.482\n",
      "epoch: 4, 0.463\n",
      "epoch: 5, 0.395\n",
      "epoch: 6, 0.378\n",
      "epoch: 7, 0.374\n",
      "epoch: 8, 0.370\n",
      "epoch: 9, 0.354\n",
      "epoch: 10, 0.324\n",
      "epoch: 11, 0.308\n",
      "epoch: 12, 0.312\n",
      "epoch: 13, 0.349\n",
      "epoch: 14, 0.243\n",
      "epoch: 15, 0.217\n",
      "epoch: 16, 0.214\n",
      "epoch: 17, 0.210\n",
      "epoch: 18, 0.206\n",
      "epoch: 19, 0.204\n",
      "epoch: 20, 0.202\n",
      "epoch: 21, 0.201\n",
      "epoch: 22, 0.200\n",
      "epoch: 23, 0.199\n",
      "epoch: 24, 0.199\n",
      "epoch: 25, 0.198\n",
      "epoch: 26, 0.198\n",
      "epoch: 27, 0.197\n",
      "epoch: 28, 0.197\n",
      "epoch: 29, 0.196\n",
      "epoch: 30, 0.196\n",
      "epoch: 31, 0.196\n",
      "epoch: 32, 0.196\n",
      "epoch: 33, 0.195\n",
      "epoch: 34, 0.195\n",
      "epoch: 35, 0.195\n",
      "epoch: 36, 0.195\n",
      "epoch: 37, 0.195\n",
      "epoch: 38, 0.195\n",
      "epoch: 39, 0.195\n",
      "epoch: 40, 0.194\n",
      "epoch: 41, 0.194\n",
      "epoch: 42, 0.194\n",
      "epoch: 43, 0.194\n",
      "epoch: 44, 0.194\n",
      "epoch: 45, 0.194\n",
      "epoch: 46, 0.194\n",
      "epoch: 47, 0.194\n",
      "epoch: 48, 0.194\n",
      "epoch: 49, 0.194\n",
      "epoch: 50, 0.194\n",
      "epoch: 51, 0.194\n",
      "epoch: 52, 0.194\n",
      "epoch: 53, 0.194\n",
      "epoch: 54, 0.194\n",
      "epoch: 55, 0.194\n",
      "epoch: 56, 0.193\n",
      "epoch: 57, 0.193\n",
      "epoch: 58, 0.193\n",
      "epoch: 59, 0.193\n"
     ]
    }
   ],
   "source": [
    "coeffs = train_model(epochs=60, lr=1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(coeffs, val_x, val_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The acc hasn't improved comparing to single NN and simple linear model, because DNN and NNs are designed to perform well when there's much data and the same is more complex."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast.ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
